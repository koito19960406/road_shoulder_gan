import os
import matplotlib.pyplot as plt
import re
import seaborn as sn
import pandas as pd
import sys
sys.path.append('src/models/')
from segmentation.color_maps import cityscapes

class TrainHistoryVisualizer:
    def __init__(self,root_dir):
        self.root_dir = root_dir
        
    def cyclegan_generate_stats_from_log(self, experiment_name, line_interval=10, nb_data=10800, enforce_last_line=True):
        """
        Generate chart with all losses from log file generated by CycleGAN/Pix2pix/CUT framework
        """
        # run if the output doesn't exist yet
        os.makedirs(f"./reports/figures/{experiment_name}", exist_ok = True)
        if os.path.exists(f"./reports/figures/{experiment_name}/train_loss.png"):
            print(f"./reports/figures/{experiment_name}/train_loss.png" + " already exists")
        else:
            #extract every lines
            with open(os.path.join(self.root_dir, "models", experiment_name, "loss_log.txt"), 'r') as f:
                lines = f.readlines()
            #choose the lines to use for plotting
            lines_for_plot = []
            for i in range(1,len(lines)):
                if (i-1) % line_interval==0:
                    lines_for_plot.append(lines[i])
            if enforce_last_line:
                lines_for_plot.append(lines[-1])
            #initialize dict with loss names
            dicts = dict()
            dicts["epoch"] = []
            parts = (lines_for_plot[0]).split(') ')[1].split(' ')
            for i in range(0, len(parts)//2):
                dicts[parts[2*i][:-1]] = []
            #extract all data
            pattern = "epoch: ([0-9]+), iters: ([0-9]+)"
            for l in lines_for_plot:
                search = re.search(pattern, l)
                try:
                    epoch = int(search.group(1))
                except:
                    continue
                epoch_floatpart = int(search.group(2))/nb_data
                dicts["epoch"].append(epoch+epoch_floatpart) #to allow several plots for the same epoch
                parts = l.split(') ')[1].split(' ')
                for i in range(0, len(parts)//2):
                    try:
                        dicts[parts[2*i][:-1]].append(float(parts[2*i+1]))
                    except:
                        dicts[parts[2*i][:-1]] = []
                        dicts[parts[2*i][:-1]].append(float(parts[2*i+1]))
            #plot everything
            plt.figure()
            for key in dicts.keys():
                # if (key != "epoch") & (key=="cycle_A"):
                if "_A" in key:
                    if "cycle" in key:
                        line_width = 1
                    else:
                        line_width =0.3
                    plt.plot(dicts["epoch"], dicts[key], label=key, linewidth=line_width)
            plt.legend(loc="best")
            plt.savefig(f"./reports/figures/{experiment_name}/train_loss.png", figsize=(3, 6))
            plt.clf()
            # plt.show()
            # plt.close()
            
    def pix2pix_generate_stats_from_log(self, experiment_name, line_interval=10, nb_data=10800, enforce_last_line=True):
        """
        Generate chart with all losses from log file generated by CycleGAN/Pix2pix/CUT framework
        """
        # run if the output doesn't exist yet
        os.makedirs(f"./reports/figures/{experiment_name}", exist_ok = True)
        if (os.path.exists(f"./reports/figures/{experiment_name}/gen_train_loss.png"))&\
            (os.path.exists(f"./reports/figures/{experiment_name}/det_train_loss.png")):
            print("Pix2Pix plot already exists")
        else:
            #extract every lines
            with open(os.path.join(self.root_dir, "models", experiment_name, "loss_log.txt"), 'r') as f:
                lines = f.readlines()
            #choose the lines to use for plotting
            lines_for_plot = []
            for i in range(1,len(lines)):
                if (i-1) % line_interval==0:
                    lines_for_plot.append(lines[i])
            if enforce_last_line:
                lines_for_plot.append(lines[-1])
            #initialize dict with loss names
            dicts = dict()
            dicts["epoch"] = []
            parts = (lines_for_plot[0]).split(') ')[1].split(' ')
            for i in range(0, len(parts)//2):
                dicts[parts[2*i][:-1]] = []
            #extract all data
            pattern = "epoch: ([0-9]+), iters: ([0-9]+)"
            for l in lines_for_plot:
                search = re.search(pattern, l)
                try:
                    epoch = int(search.group(1))
                except:
                    continue
                epoch_floatpart = int(search.group(2))/nb_data
                dicts["epoch"].append(epoch+epoch_floatpart) #to allow several plots for the same epoch
                parts = l.split(') ')[1].split(' ')
                for i in range(0, len(parts)//2):
                    try:
                        dicts[parts[2*i][:-1]].append(float(parts[2*i+1]))
                    except:
                        dicts[parts[2*i][:-1]] = []
                        dicts[parts[2*i][:-1]].append(float(parts[2*i+1]))
            #plot generator loss
            plt.figure()
            for key in dicts.keys():
                if (key != "epoch")&("D_" not in key):
                    plt.plot(dicts["epoch"], dicts[key], label=key, linewidth=0.5)
            plt.legend(loc="best")
            plt.savefig(f"./reports/figures/{experiment_name}/gen_train_loss.png", figsize=(3, 6))
            plt.clf()
            
            #plot detector loss
            plt.figure()
            for key in dicts.keys():
                if (key != "epoch")&("G_" not in key):
                    plt.plot(dicts["epoch"], dicts[key], label=key, linewidth=0.5)
            plt.legend(loc="best")
            plt.savefig(f"./reports/figures/{experiment_name}/det_train_loss.png", figsize=(3, 6))
            plt.clf()
            
class SegCorrVisualizer:
    """class to visualize correlation matrix of segmentation results
    """
    
    def __init__(self, input_file, output_file, label_list):
        self.input_file = input_file
        self.output_file = output_file
        self.label_list = label_list
        
    def plot(self):
        # read csv and retain all the columns except for pid col (first col)
        df = pd.read_csv(self.input_file).iloc[:,1:]
        for label in self.label_list:
            df_filtered = df.filter(regex=label.name)
            if len(df_filtered.columns) > 0:
                corrMatrix = df_filtered.corr()
                fig, ax = plt.subplots()
                sn.set(rc={"figure.figsize":(8, 8)})
                sn.heatmap(corrMatrix, annot = True)
                plt.xticks(rotation=90, size = 20)
                plt.yticks(rotation=0, size = 20)
                fig.tight_layout()
                plt.savefig(os.path.join(self.output_file, f"segmentation_correlation_matrix_{label.name}.pdf"))
                plt.clf()
        
if __name__ == '__main__':
    root_dir = "/Volumes/ExFAT 1/road_shoulder_gan"
    # train loss plot
    for experiment_name in os.listdir(os.path.join(root_dir,"models")):
        if not experiment_name.startswith('.'):  
            visualizer = TrainHistoryVisualizer(root_dir)
            if "cyclegan" in experiment_name:
                visualizer.cyclegan_generate_stats_from_log(experiment_name, line_interval=10, nb_data=3473)
            if "pix2pix" in experiment_name:
                visualizer.pix2pix_generate_stats_from_log(experiment_name, line_interval=10, nb_data=3473)
    
            # segmentation result correlation plot
            input_file = os.path.join(root_dir, "data/processed",experiment_name,"segmentation_result/segmentation_result.csv")
            output_folder = f"./reports/figures/{experiment_name}"
            label_list = cityscapes.create_cityscapes_label_colormap()
            segcorr = SegCorrVisualizer(input_file, output_folder, label_list)
            try:
                segcorr.plot()
            except Exception as e:
                print(e)
                pass