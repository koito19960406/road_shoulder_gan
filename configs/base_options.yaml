##### basic parameters
gpu_ids: '0' # gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU
checkpoints_dir: './checkpoints' # models are saved here

##### model parameters
input_nc: '3' # no. of input image channels: 3 for RGB and 1 for grayscale
output_nc: '3' # no. of output image channels: 3 for RGB and 1 for grayscale
ngf: '64' # no. of gen filters in the last conv layer
ndf: '64' # no. of discrim filters in the first conv layer
netD: 'basic' # specify discriminator architecture [basic | n_layers | pixel]. The basic model is a 70x70 PatchGAN. n_layers allows you to specify the layers in the discriminator
netG: 'resnet_9blocks' # specify generator architecture [resnet_9blocks | resnet_6blocks | unet_256 | unet_128]
n_layers_D: '3' # only used if netD==n_layers
norm: 'instance' # instance normalization or batch normalization [instance | batch | none]
init_type: 'normal' # network initialization [normal | xavier | kaiming | orthogonal]
init_gain: '0.02' # scaling factor for normal, xavier and orthogonal.
no_dropout: True

##### dataset parameters
direction: 'AtoB' # AtoB or BtoA
serial_batches: True # if true, takes images in order to make batches, otherwise takes them randomly
num_threads: '4' # no. threads for loading data
batch_size: '1' # input batch size
load_size: '286' # scale images to this size
crop_size: '256' # then crop to this size
preprocess: 'resize_and_crop' # scaling and cropping of images at load time [resize_and_crop | crop | scale_width | scale_width_and_crop | none]
no_flip: True # if specified, do not flip the images for data augmentation
display_winsize: '256' # display window size for both visdom and HTML

##### additional parameters
epoch: 'latest' # which epoch to load? set to latest to use latest cached model'
load_iter: '0' # which iteration to load? if load_iter > 0, the code will load models by iter_[load_iter]; otherwise, the code will load models by [epoch]
verbose: True

##### wandb parameters
use_wandb: True
 # wandb_project_name # should be same as experiment name